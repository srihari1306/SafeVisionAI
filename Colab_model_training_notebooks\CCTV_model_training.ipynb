{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjvHUVBEyBntrjb90ww7wR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srihari1306/SafeVisionAI/blob/srihari/Colab_model_training_notebooks%5CCCTV_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_3-SKu1bvVt",
        "outputId": "f2a4e2d0-426b-407b-a05d-d6c1e26041b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "CELL 1: ENVIRONMENT SETUP\n",
            "======================================================================\n",
            "Mounted at /content/drive\n",
            "\n",
            "[INFO] Installing required libraries...\n",
            "\n",
            "[INFO] Extracting dataset...\n",
            "[SUCCESS] Dataset extracted to: /content/hwid12_data\n",
            "\n",
            "[INFO] Dataset structure:\n",
            "hwid12_data/\n",
            "  Video-Accident-Dataset/\n",
            "\n",
            "======================================================================\n",
            "SETUP COMPLETE!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 1: SETUP - Mount Drive, Unzip Dataset, Install Dependencies\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 1: ENVIRONMENT SETUP\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required libraries\n",
        "print(\"\\n[INFO] Installing required libraries...\")\n",
        "!pip install -q opencv-python-headless tqdm scikit-learn\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Define paths\n",
        "DATASET_ZIP = '/content/drive/MyDrive/archive.zip'\n",
        "EXTRACT_TO = '/content/hwid12_data'\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/accident_video_model.h5'\n",
        "\n",
        "# Unzip dataset\n",
        "print(\"\\n[INFO] Extracting dataset...\")\n",
        "if os.path.exists(EXTRACT_TO):\n",
        "    shutil.rmtree(EXTRACT_TO)\n",
        "\n",
        "os.makedirs(EXTRACT_TO, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(DATASET_ZIP, 'r') as zip_ref:\n",
        "    zip_ref.extractall(EXTRACT_TO)\n",
        "\n",
        "print(f\"[SUCCESS] Dataset extracted to: {EXTRACT_TO}\")\n",
        "\n",
        "# List extracted folders\n",
        "print(\"\\n[INFO] Dataset structure:\")\n",
        "for root, dirs, files in os.walk(EXTRACT_TO):\n",
        "    level = root.replace(EXTRACT_TO, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f'{indent}{os.path.basename(root)}/')\n",
        "    if level < 2:  # Only show first 2 levels\n",
        "        subindent = ' ' * 2 * (level + 1)\n",
        "        for dir_name in dirs[:5]:  # Show first 5 folders\n",
        "            print(f'{subindent}{dir_name}/')\n",
        "        if len(dirs) > 5:\n",
        "            print(f'{subindent}... and {len(dirs) - 5} more folders')\n",
        "    if level == 0:\n",
        "        break\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SETUP COMPLETE!\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL A: PREPROCESS & CACHE VIDEO FRAMES (OPTIMIZED)\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "\n",
        "\n",
        "DATASET_ROOT = \"/content/hwid12_data\"\n",
        "CACHE_DIR = \"/content/processed_frames\"\n",
        "SEQUENCE_LENGTH = 50\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "records = []\n",
        "\n",
        "print(\"[INFO] Scanning dataset...\")\n",
        "\n",
        "video_files = []\n",
        "video_files += glob.glob(os.path.join(DATASET_ROOT, \"**\", \"*.mp4\"), recursive=True)\n",
        "video_files += glob.glob(os.path.join(DATASET_ROOT, \"**\", \"*.avi\"), recursive=True)\n",
        "\n",
        "print(f\"[INFO] Found {len(video_files)} total videos. Starting processing...\")\n",
        "\n",
        "for vid_path in tqdm(video_files):\n",
        "    try:\n",
        "        folder_name = os.path.basename(os.path.dirname(vid_path)).lower()\n",
        "        if \"negative\" in folder_name or \"normal\" in folder_name:\n",
        "            label = 0\n",
        "        else:\n",
        "            label = 1\n",
        "\n",
        "        cap = cv2.VideoCapture(vid_path)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        if total_frames <= SEQUENCE_LENGTH:\n",
        "            indices = np.arange(total_frames)\n",
        "        else:\n",
        "            indices = np.linspace(0, total_frames - 1, SEQUENCE_LENGTH).astype(int)\n",
        "\n",
        "        frames = []\n",
        "        current_frame = 0\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if current_frame in indices:\n",
        "                frame = cv2.resize(frame, (IMG_WIDTH, IMG_HEIGHT))\n",
        "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                frames.append(frame)\n",
        "\n",
        "            current_frame += 1\n",
        "            # Optimization: Stop reading if we have enough frames\n",
        "            if len(frames) == len(indices):\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        # Convert to numpy array\n",
        "        # CRITICAL: Use uint8 (0-255) to save disk space!\n",
        "        frames = np.array(frames, dtype=np.uint8)\n",
        "\n",
        "        # Handle Padding (if video was short)\n",
        "        if len(frames) < SEQUENCE_LENGTH:\n",
        "            padding = np.zeros((SEQUENCE_LENGTH - len(frames), IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)\n",
        "            frames = np.concatenate([frames, padding], axis=0)\n",
        "\n",
        "        # Truncate (safety)\n",
        "        frames = frames[:SEQUENCE_LENGTH]\n",
        "\n",
        "        # Generate unique filename\n",
        "        # Hash or index based name is safer than original filename to avoid duplicates\n",
        "        file_name = f\"{len(records)}_{label}.npy\"\n",
        "        save_path = os.path.join(CACHE_DIR, file_name)\n",
        "\n",
        "        np.save(save_path, frames)\n",
        "        records.append([save_path, label])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Failed {vid_path}: {e}\")\n",
        "\n",
        "# Save Metadata\n",
        "df = pd.DataFrame(records, columns=[\"npy_path\", \"label\"])\n",
        "df.to_csv(os.path.join(CACHE_DIR, \"metadata.csv\"), index=False)\n",
        "\n",
        "print(f\"\\n[SUCCESS] Processed {len(df)} videos.\")\n",
        "print(f\"Frames saved as uint8 at: {CACHE_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lREp-_lrb3NW",
        "outputId": "3d3dab9c-3808-48d9-be05-91cbc9edf94f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Scanning dataset...\n",
            "[INFO] Found 2782 total videos. Starting processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2782/2782 [44:31<00:00,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUCCESS] Processed 2782 videos.\n",
            "Frames saved as uint8 at: /content/processed_frames\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL B: FAST .NPY DATA GENERATOR\n",
        "# ============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "CACHE_DIR = \"/content/processed_frames\"\n",
        "\n",
        "# Check if metadata exists\n",
        "if not os.path.exists(f\"{CACHE_DIR}/metadata.csv\"):\n",
        "    raise FileNotFoundError(\"Metadata not found! Run Cell A first.\")\n",
        "\n",
        "df = pd.read_csv(f\"{CACHE_DIR}/metadata.csv\")\n",
        "\n",
        "# Stratified Split\n",
        "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"label\"]\n",
        ")\n",
        "print(f\"Training Samples: {len(train_df)}\")\n",
        "print(f\"Validation Samples: {len(val_df)}\")\n",
        "print(f\"Testing Samples: {len(test_df)}\")\n",
        "\n",
        "class FastNumpyGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, df, batch_size=16, shuffle=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.df))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        idxs = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        batch_df = self.df.iloc[idxs]\n",
        "\n",
        "        X = []\n",
        "        y = []\n",
        "\n",
        "        for _, row in batch_df.iterrows():\n",
        "            # Load uint8 array (0-255)\n",
        "            data = np.load(row[\"npy_path\"])\n",
        "\n",
        "            # Normalize to float32 (0-1) HERE to save memory during storage\n",
        "            data = data.astype('float32') / 255.0\n",
        "\n",
        "            X.append(data)\n",
        "            y.append(row[\"label\"])\n",
        "\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "# Note: Batch size can be higher now because reading .npy is efficient\n",
        "train_generator = FastNumpyGenerator(train_df, batch_size=16, shuffle=True)\n",
        "val_generator = FastNumpyGenerator(val_df, batch_size=16, shuffle=False)\n",
        "test_generator = FastNumpyGenerator(test_df, batch_size=16, shuffle=False)\n",
        "\n",
        "print(\"[INFO] FAST Generators ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3K2_OdSb5R-",
        "outputId": "9852d0be-389c-49ed-c9d0-38cafb30d03d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Samples: 2225\n",
            "Validation Samples: 278\n",
            "Testing Samples: 279\n",
            "[INFO] FAST Generators ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 3: MODEL TRAINING (FIXED INPUT SHAPE)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 3: MODEL TRAINING\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "SEQUENCE_LENGTH = 50\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/accident_video_model.h5'\n",
        "\n",
        "def create_model():\n",
        "    input_layer = layers.Input(shape=(SEQUENCE_LENGTH, IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "    cnn = MobileNetV2(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
        "        pooling='avg'\n",
        "    )\n",
        "    cnn.trainable = False\n",
        "\n",
        "    x = layers.TimeDistributed(cnn)(input_layer)\n",
        "\n",
        "    x = layers.LSTM(64, return_sequences=False)(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = keras.Model(inputs=input_layer, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
        ")\n",
        "\n",
        "print(\"[INFO] Model built with input shape:\", model.input_shape)\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(MODEL_SAVE_PATH, save_best_only=True, monitor='val_loss', verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iivjzRkAb7IK",
        "outputId": "043a05ed-1bac-4158-8095-7f19086e686f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 3: MODEL TRAINING\n",
            "======================================================================\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "[INFO] Model built with input shape: (None, 50, 224, 224, 3)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7491 - auc: 0.8097 - loss: 0.5191\n",
            "Epoch 1: val_loss improved from inf to 0.15544, saving model to /content/drive/MyDrive/accident_video_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 2s/step - accuracy: 0.7497 - auc: 0.8105 - loss: 0.5181 - val_accuracy: 0.9659 - val_auc: 0.9929 - val_loss: 0.1554 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9435 - auc: 0.9854 - loss: 0.1873\n",
            "Epoch 2: val_loss improved from 0.15544 to 0.11462, saving model to /content/drive/MyDrive/accident_video_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 2s/step - accuracy: 0.9435 - auc: 0.9854 - loss: 0.1871 - val_accuracy: 0.9659 - val_auc: 0.9930 - val_loss: 0.1146 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9620 - auc: 0.9902 - loss: 0.1249\n",
            "Epoch 3: val_loss improved from 0.11462 to 0.08260, saving model to /content/drive/MyDrive/accident_video_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 2s/step - accuracy: 0.9620 - auc: 0.9902 - loss: 0.1249 - val_accuracy: 0.9749 - val_auc: 0.9971 - val_loss: 0.0826 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9721 - auc: 0.9946 - loss: 0.0984\n",
            "Epoch 4: val_loss improved from 0.08260 to 0.06651, saving model to /content/drive/MyDrive/accident_video_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 2s/step - accuracy: 0.9721 - auc: 0.9946 - loss: 0.0983 - val_accuracy: 0.9785 - val_auc: 0.9975 - val_loss: 0.0665 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9768 - auc: 0.9939 - loss: 0.0819\n",
            "Epoch 5: val_loss improved from 0.06651 to 0.06594, saving model to /content/drive/MyDrive/accident_video_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 2s/step - accuracy: 0.9768 - auc: 0.9939 - loss: 0.0818 - val_accuracy: 0.9785 - val_auc: 0.9974 - val_loss: 0.0659 - learning_rate: 1.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9799 - auc: 0.9964 - loss: 0.0644\n",
            "Epoch 6: val_loss improved from 0.06594 to 0.06333, saving model to /content/drive/MyDrive/accident_video_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 2s/step - accuracy: 0.9799 - auc: 0.9964 - loss: 0.0644 - val_accuracy: 0.9749 - val_auc: 0.9983 - val_loss: 0.0633 - learning_rate: 1.0000e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9846 - auc: 0.9957 - loss: 0.0650\n",
            "Epoch 7: val_loss did not improve from 0.06333\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 2s/step - accuracy: 0.9847 - auc: 0.9957 - loss: 0.0649 - val_accuracy: 0.9767 - val_auc: 0.9969 - val_loss: 0.0702 - learning_rate: 1.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9842 - auc: 0.9982 - loss: 0.0486\n",
            "Epoch 8: val_loss improved from 0.06333 to 0.06305, saving model to /content/drive/MyDrive/accident_video_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 2s/step - accuracy: 0.9842 - auc: 0.9982 - loss: 0.0486 - val_accuracy: 0.9803 - val_auc: 0.9980 - val_loss: 0.0630 - learning_rate: 1.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9884 - auc: 0.9986 - loss: 0.0405\n",
            "Epoch 9: val_loss did not improve from 0.06305\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 2s/step - accuracy: 0.9884 - auc: 0.9987 - loss: 0.0405 - val_accuracy: 0.9785 - val_auc: 0.9986 - val_loss: 0.0671 - learning_rate: 1.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9881 - auc: 0.9971 - loss: 0.0427\n",
            "Epoch 10: val_loss improved from 0.06305 to 0.05630, saving model to /content/drive/MyDrive/accident_video_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 2s/step - accuracy: 0.9881 - auc: 0.9971 - loss: 0.0427 - val_accuracy: 0.9803 - val_auc: 0.9968 - val_loss: 0.0563 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 10.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/accident_video_model.h5\"\n",
        "\n",
        "print(\"Loading trained model from:\", MODEL_SAVE_PATH)\n",
        "model = load_model(MODEL_SAVE_PATH)\n",
        "\n",
        "print(\"[INFO] Model loaded successfully!\")\n",
        "print(\"Model Input Shape:\", model.input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHqHIVAcdhwV",
        "outputId": "40041e6d-419a-4199-dbad-00171d340fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading trained model from: /content/drive/MyDrive/accident_video_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Model loaded successfully!\n",
            "Model Input Shape: (None, 50, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save final model\n",
        "model.save(MODEL_SAVE_PATH)\n",
        "print(f\"\\n[SUCCESS] Model saved to: {MODEL_SAVE_PATH}\")\n",
        "\n",
        "# Training results\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Final Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
        "print(f\"Final Training Loss: {history.history['loss'][-1]:.4f}\")\n",
        "print(f\"Final Validation Loss: {history.history['val_loss'][-1]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMweorOWcC07",
        "outputId": "1a2de69f-9db0-400d-8f39-a033b35da8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUCCESS] Model saved to: /content/drive/MyDrive/accident_video_model.h5\n",
            "\n",
            "======================================================================\n",
            "TRAINING COMPLETE!\n",
            "======================================================================\n",
            "Final Training Accuracy: 0.9888\n",
            "Final Validation Accuracy: 0.9803\n",
            "Final Training Loss: 0.0389\n",
            "Final Validation Loss: 0.0563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL EVALUATION ON TEST SET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "y_true = test_df[\"label\"].values\n",
        "\n",
        "start_time = time.time()\n",
        "y_pred_probs = model.predict(test_generator)\n",
        "end_time = time.time()\n",
        "\n",
        "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "try:\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_probs)\n",
        "except:\n",
        "    roc_auc = \"Undefined (only one class present)\"\n",
        "\n",
        "num_samples = len(test_generator.df)\n",
        "total_time = end_time - start_time\n",
        "avg_latency = (total_time / num_samples) * 1000\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc}\")\n",
        "print(f\"Average Inference Latency: {avg_latency:.2f} ms/video\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyh1_QIqPzi4",
        "outputId": "b632c5ab-673d-401f-f948-6f71b0a8f7c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "MODEL EVALUATION ON TEST SET\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 5s/step\n",
            "Accuracy: 0.9857\n",
            "Precision: 0.9939\n",
            "Recall: 0.9820\n",
            "F1-Score: 0.9880\n",
            "ROC-AUC: 0.9990911035072711\n",
            "Average Inference Latency: 734.96 ms/video\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 4: INFERENCE ON CUSTOM VIDEO (FIXED RESOLUTION)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 4: VIDEO INFERENCE & DETECTION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from collections import deque\n",
        "from google.colab import files\n",
        "\n",
        "TEST_VIDEO_PATH = '/content/drive/MyDrive/demo.mp4'\n",
        "OUTPUT_VIDEO_PATH = '/content/output_detected.mp4'\n",
        "MODEL_PATH = '/content/drive/MyDrive/accident_video_model.h5'\n",
        "\n",
        "SEQUENCE_LENGTH = 50\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "CONFIDENCE_THRESHOLD = 0.5\n",
        "\n",
        "\n",
        "def create_mobilenet_lstm_model(sequence_length=50, img_height=224, img_width=224):\n",
        "    input_layer = layers.Input(shape=(sequence_length, img_height, img_width, 3))\n",
        "\n",
        "    mobilenet = MobileNetV2(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=(img_height, img_width, 3),\n",
        "        pooling='avg'\n",
        "    )\n",
        "    mobilenet.trainable = False\n",
        "\n",
        "    x = layers.TimeDistributed(mobilenet)(input_layer)\n",
        "    x = layers.LSTM(64, return_sequences=False)(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    output_layer = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "print(\"\\n[INFO] Loading trained model...\")\n",
        "try:\n",
        "    model = keras.models.load_model(MODEL_PATH)\n",
        "    print(\"[SUCCESS] Model loaded directly\")\n",
        "except:\n",
        "    print(\"[INFO] Recreating model architecture...\")\n",
        "    model = create_mobilenet_lstm_model(SEQUENCE_LENGTH, IMG_HEIGHT, IMG_WIDTH)\n",
        "    model.load_weights(MODEL_PATH)\n",
        "    print(\"[SUCCESS] Model weights loaded\")\n",
        "\n",
        "if not os.path.exists(TEST_VIDEO_PATH):\n",
        "    print(f\"\\n[WARNING] Test video not found at: {TEST_VIDEO_PATH}\")\n",
        "    print(\"[INFO] Please upload your test video to Google Drive or update the path\")\n",
        "else:\n",
        "    print(f\"\\n[INFO] Processing video: {TEST_VIDEO_PATH}\")\n",
        "\n",
        "    cap = cv2.VideoCapture(TEST_VIDEO_PATH)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(\"[ERROR] Failed to open video file\")\n",
        "    else:\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        print(f\"[INFO] Video properties:\")\n",
        "        print(f\"   Resolution: {width}x{height}\")\n",
        "        print(f\"   FPS: {fps}\")\n",
        "        print(f\"   Total frames: {total_frames}\")\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, fps, (width, height))\n",
        "\n",
        "        frame_queue = deque(maxlen=SEQUENCE_LENGTH)\n",
        "\n",
        "        print(\"\\n[INFO] Processing frames...\")\n",
        "        from tqdm import tqdm\n",
        "        progress_bar = tqdm(total=total_frames, desc=\"Processing\")\n",
        "\n",
        "        frame_count = 0\n",
        "        detection_label = \"BUFFERING...\"\n",
        "        detection_color = (0, 255, 255)\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            processed_frame = cv2.resize(frame, (IMG_WIDTH, IMG_HEIGHT))\n",
        "            processed_frame_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)\n",
        "            processed_frame_rgb = processed_frame_rgb.astype(np.float32) / 255.0\n",
        "\n",
        "            frame_queue.append(processed_frame_rgb)\n",
        "\n",
        "            if len(frame_queue) == SEQUENCE_LENGTH:\n",
        "                sequence = np.array(list(frame_queue))\n",
        "                sequence = np.expand_dims(sequence, axis=0)\n",
        "\n",
        "                if frame_count % 5 == 0:\n",
        "                    prediction = model.predict(sequence, verbose=0)[0][0]\n",
        "\n",
        "                    if prediction > CONFIDENCE_THRESHOLD:\n",
        "                        detection_label = f\"ACCIDENT! ({prediction:.0%})\"\n",
        "                        detection_color = (0, 0, 255)  # Red\n",
        "                    else:\n",
        "                        detection_label = f\"NORMAL ({prediction:.0%})\"\n",
        "                        detection_color = (0, 255, 0)  # Green\n",
        "\n",
        "            cv2.rectangle(frame, (0, 0), (width, 60), (0, 0, 0), -1)\n",
        "            cv2.putText(\n",
        "                frame,\n",
        "                detection_label,\n",
        "                (20, 45),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                1.0,\n",
        "                detection_color,\n",
        "                2,\n",
        "                cv2.LINE_AA\n",
        "            )\n",
        "\n",
        "            out.write(frame)\n",
        "            frame_count += 1\n",
        "            progress_bar.update(1)\n",
        "\n",
        "        progress_bar.close()\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        print(f\"\\n[SUCCESS] Processed {frame_count} frames\")\n",
        "        print(f\"[SUCCESS] Output saved to: {OUTPUT_VIDEO_PATH}\")\n",
        "\n",
        "        print(\"\\n[INFO] Downloading output video...\")\n",
        "        try:\n",
        "            files.download(OUTPUT_VIDEO_PATH)\n",
        "            print(\"[SUCCESS] Video downloaded to your computer!\")\n",
        "        except Exception as e:\n",
        "            print(f\"[WARNING] Auto-download failed: {str(e)}\")\n",
        "            print(f\"[INFO] You can manually download from: {OUTPUT_VIDEO_PATH}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"INFERENCE COMPLETE!\")\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "frlxtBMoFo5G",
        "outputId": "e11a886b-60e3-4275-bde5-039a849f0ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "CELL 4: VIDEO INFERENCE & DETECTION\n",
            "======================================================================\n",
            "\n",
            "[INFO] Loading trained model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUCCESS] Model loaded directly\n",
            "\n",
            "[INFO] Processing video: /content/drive/MyDrive/demo.mp4\n",
            "[INFO] Video properties:\n",
            "   Resolution: 848x382\n",
            "   FPS: 24\n",
            "   Total frames: 268\n",
            "\n",
            "[INFO] Processing frames...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 268/268 [01:19<00:00,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUCCESS] Processed 268 frames\n",
            "[SUCCESS] Output saved to: /content/output_detected.mp4\n",
            "\n",
            "[INFO] Downloading output video...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7dcd1e9b-4005-429d-ad91-39e3b2b6cb83\", \"output_detected.mp4\", 1863654)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUCCESS] Video downloaded to your computer!\n",
            "\n",
            "======================================================================\n",
            "INFERENCE COMPLETE!\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "II4i-499FxoK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}